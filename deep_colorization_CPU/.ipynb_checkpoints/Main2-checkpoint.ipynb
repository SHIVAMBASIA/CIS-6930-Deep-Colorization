{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of given Image List 750\n",
      "Number of images -  751\n",
      "Training Set Size :  675\n",
      "Test Set Size :  76\n",
      "Length of training Image List 674\n",
      "Length of testing Image List 76\n",
      "For Sigmoid Function\n",
      "Device: cpu\n",
      "Length of Augmented Dataset 6740\n",
      "Activation Function:  sigmoid\n",
      "..Colorizer Training started..\n",
      "epoch: 0, loss: 0.5015137915033847\n",
      "epoch: 1, loss: 0.1348688721191138\n",
      "epoch: 2, loss: 0.10964369689463638\n",
      "epoch: 3, loss: 0.08466222259448841\n",
      "epoch: 4, loss: 0.07582751967129298\n",
      "epoch: 5, loss: 0.0701897946128156\n",
      "epoch: 6, loss: 0.06512453952746\n",
      "epoch: 7, loss: 0.062144202369381674\n",
      "epoch: 8, loss: 0.059637726430082694\n",
      "epoch: 9, loss: 0.05820070140180178\n",
      "epoch: 10, loss: 0.056139788270229474\n",
      "epoch: 11, loss: 0.05360016210761387\n",
      "epoch: 12, loss: 0.05334676387428772\n",
      "epoch: 13, loss: 0.05255916864553001\n",
      "epoch: 14, loss: 0.050985581139684655\n",
      "epoch: 15, loss: 0.04907789961725939\n",
      "epoch: 16, loss: 0.04705964037566446\n",
      "epoch: 17, loss: 0.04740385113109369\n",
      "epoch: 18, loss: 0.046856661239871755\n",
      "epoch: 19, loss: 0.04598537592391949\n",
      "epoch: 20, loss: 0.045103292737621814\n",
      "epoch: 21, loss: 0.04491621188935824\n",
      "epoch: 22, loss: 0.04403498138708528\n",
      "epoch: 23, loss: 0.04266785440267995\n",
      "epoch: 24, loss: 0.0421375245496165\n",
      "epoch: 25, loss: 0.0431029890460195\n",
      "epoch: 26, loss: 0.04082103147811722\n",
      "epoch: 27, loss: 0.041672933293739334\n",
      "epoch: 28, loss: 0.039533560469863005\n",
      "epoch: 29, loss: 0.039796934914193116\n",
      "epoch: 30, loss: 0.039091624290449545\n",
      "epoch: 31, loss: 0.03897295023489278\n",
      "epoch: 32, loss: 0.0394181977462722\n",
      "epoch: 33, loss: 0.03987154265632853\n",
      "epoch: 34, loss: 0.03897943832271267\n",
      "epoch: 35, loss: 0.037219820311293006\n",
      "epoch: 36, loss: 0.038753808054025285\n",
      "epoch: 37, loss: 0.03825163043802604\n",
      "epoch: 38, loss: 0.03810745531518478\n",
      "epoch: 39, loss: 0.03711816311988514\n",
      "epoch: 40, loss: 0.03626869209983852\n",
      "epoch: 41, loss: 0.036205324897309765\n",
      "epoch: 42, loss: 0.036525390889437404\n",
      "epoch: 43, loss: 0.036294284524046816\n",
      "epoch: 44, loss: 0.036141547869192436\n",
      "epoch: 45, loss: 0.03514173549046973\n",
      "epoch: 46, loss: 0.03517696131893899\n",
      "epoch: 47, loss: 0.035274825138913\n",
      "epoch: 48, loss: 0.03601205534505425\n",
      "epoch: 49, loss: 0.03491644137102412\n",
      "epoch: 50, loss: 0.03393159266852308\n",
      "epoch: 51, loss: 0.03414142024121247\n",
      "epoch: 52, loss: 0.034582480519020464\n",
      "epoch: 53, loss: 0.03267548719304614\n",
      "epoch: 54, loss: 0.03313739408622496\n",
      "epoch: 55, loss: 0.03261360757460352\n",
      "epoch: 56, loss: 0.03237299666216131\n",
      "epoch: 57, loss: 0.03267703550227452\n",
      "epoch: 58, loss: 0.03283142072905321\n",
      "epoch: 59, loss: 0.03111871337023331\n",
      "epoch: 60, loss: 0.03215630267368397\n",
      "epoch: 61, loss: 0.031157114048255607\n",
      "epoch: 62, loss: 0.031066762887348887\n",
      "epoch: 63, loss: 0.029949003212095704\n",
      "epoch: 64, loss: 0.03118540748982923\n",
      "epoch: 65, loss: 0.030710743994859513\n",
      "epoch: 66, loss: 0.030098940056632273\n",
      "epoch: 67, loss: 0.029788736370392144\n",
      "epoch: 68, loss: 0.029484798818884883\n",
      "epoch: 69, loss: 0.029862513256375678\n",
      "epoch: 70, loss: 0.030718169662577566\n",
      "epoch: 71, loss: 0.029160060548747424\n",
      "epoch: 72, loss: 0.02825299019605154\n",
      "epoch: 73, loss: 0.029702898922550958\n",
      "epoch: 74, loss: 0.02927425256348215\n",
      "epoch: 75, loss: 0.029379340216109995\n",
      "epoch: 76, loss: 0.029020217822107952\n",
      "epoch: 77, loss: 0.028899976547108963\n",
      "epoch: 78, loss: 0.028826985995692667\n",
      "epoch: 79, loss: 0.02753043678967515\n",
      "epoch: 80, loss: 0.02696581996860914\n",
      "epoch: 81, loss: 0.027548277052119374\n",
      "epoch: 82, loss: 0.027855039792484604\n",
      "epoch: 83, loss: 0.028352344474114943\n",
      "epoch: 84, loss: 0.027585693722357973\n",
      "epoch: 85, loss: 0.02753658279107185\n",
      "epoch: 86, loss: 0.02717778302030638\n",
      "epoch: 87, loss: 0.027512328197190072\n",
      "epoch: 88, loss: 0.026730856239737477\n",
      "epoch: 89, loss: 0.026673557600588538\n",
      "epoch: 90, loss: 0.027232680818997324\n",
      "epoch: 91, loss: 0.027330195385729894\n",
      "epoch: 92, loss: 0.026705907359428238\n",
      "epoch: 93, loss: 0.02606514547369443\n",
      "epoch: 94, loss: 0.026241089202812873\n",
      "epoch: 95, loss: 0.02631681280763587\n",
      "epoch: 96, loss: 0.026133236962778028\n",
      "epoch: 97, loss: 0.026228496884868946\n",
      "epoch: 98, loss: 0.025317658648418728\n",
      "epoch: 99, loss: 0.0261489185213577\n",
      "sigmoid\n",
      "..Colorizer Test started..\n",
      "Image: 1, loss: 0.00039424648275598884\n",
      "Image: 2, loss: 0.0003324140270706266\n",
      "Image: 3, loss: 0.0006072878604754806\n",
      "Image: 4, loss: 0.000253091478953138\n",
      "Image: 5, loss: 0.0007549689034931362\n",
      "Image: 6, loss: 0.0005041547701694071\n",
      "Image: 7, loss: 0.0010958551429212093\n",
      "Image: 8, loss: 0.00033212307607755065\n",
      "Image: 9, loss: 0.0007045650854706764\n",
      "Image: 10, loss: 0.000669380824547261\n",
      "Image: 11, loss: 0.0002373920287936926\n",
      "Image: 12, loss: 8.426470594713464e-05\n",
      "Image: 13, loss: 0.0004981588572263718\n",
      "Image: 14, loss: 0.00030140962917357683\n",
      "Image: 15, loss: 0.0005358516937121749\n",
      "Image: 16, loss: 0.0008832463645376265\n",
      "Image: 17, loss: 0.00019268003234174103\n",
      "Image: 18, loss: 0.00022056281159166247\n",
      "Image: 19, loss: 0.00022188179718796164\n",
      "Image: 20, loss: 0.0004220203263685107\n",
      "Image: 21, loss: 0.0005501817213371396\n",
      "Image: 22, loss: 0.0006953940610401332\n",
      "Image: 23, loss: 0.00020294866408221424\n",
      "Image: 24, loss: 0.00048270844854414463\n",
      "Image: 25, loss: 0.000739912677090615\n",
      "Image: 26, loss: 0.00018160324543714523\n",
      "Image: 27, loss: 0.00024146099167410284\n",
      "Image: 28, loss: 0.00011610035289777443\n",
      "Image: 29, loss: 0.0003306845319457352\n",
      "Image: 30, loss: 0.0005461783148348331\n",
      "Image: 31, loss: 0.00021345686400309205\n",
      "Image: 32, loss: 0.0002313951845280826\n",
      "Image: 33, loss: 0.00019105925457552075\n",
      "Image: 34, loss: 0.0002670148969627917\n",
      "Image: 35, loss: 0.0007450463017448783\n",
      "Image: 36, loss: 0.00029924241243861616\n",
      "Image: 37, loss: 0.00021560964523814619\n",
      "Image: 38, loss: 0.00015753053594380617\n",
      "Image: 39, loss: 0.0002851264725904912\n",
      "Image: 40, loss: 0.0005640184972435236\n",
      "Image: 41, loss: 0.0010026603704318404\n",
      "Image: 42, loss: 0.0009540662285871804\n",
      "Image: 43, loss: 0.000536259263753891\n",
      "Image: 44, loss: 0.0006410208879970014\n",
      "Image: 45, loss: 0.00020050318562425673\n",
      "Image: 46, loss: 0.0002238982415292412\n",
      "Image: 47, loss: 0.0011416658526286483\n",
      "Image: 48, loss: 0.00028410565573722124\n",
      "Image: 49, loss: 0.0004952785675413907\n",
      "Image: 50, loss: 0.0003879801952280104\n",
      "Image: 51, loss: 0.00019169585721101612\n",
      "Image: 52, loss: 0.0002510085760150105\n",
      "Image: 53, loss: 0.00016923135262914002\n",
      "Image: 54, loss: 0.00041095164488069713\n",
      "Image: 55, loss: 0.0004428816610015929\n",
      "Image: 56, loss: 0.0005969342309981585\n",
      "Image: 57, loss: 0.0008676634170114994\n",
      "Image: 58, loss: 0.0006441088044084609\n",
      "Image: 59, loss: 0.00035020074574276805\n",
      "Image: 60, loss: 0.0005206146743148565\n",
      "Image: 61, loss: 0.0013445010408759117\n",
      "Image: 62, loss: 0.00017070368630811572\n",
      "Image: 63, loss: 0.0003673702012747526\n",
      "Image: 64, loss: 0.0004087227862328291\n",
      "Image: 65, loss: 0.0005199381266720593\n",
      "Image: 66, loss: 0.00036102128797210753\n",
      "Image: 67, loss: 0.0002410725865047425\n",
      "Image: 68, loss: 0.0005362426163628697\n",
      "Image: 69, loss: 0.000480157119454816\n",
      "Image: 70, loss: 0.00022707393509335816\n",
      "Image: 71, loss: 0.0001857158204074949\n",
      "Image: 72, loss: 0.0003783464781008661\n",
      "Image: 73, loss: 0.00040219296352006495\n",
      "Image: 74, loss: 0.0005964255542494357\n",
      "Image: 75, loss: 0.0002529275952838361\n",
      "Image: 76, loss: 0.00036154777626506984\n",
      "..Regressor training started..\n",
      "epoch: 0, loss: 0.5986322244280018\n",
      "epoch: 1, loss: 0.10627437524090055\n",
      "epoch: 2, loss: 0.0654160966805648\n",
      "epoch: 3, loss: 0.05555046835070243\n",
      "epoch: 4, loss: 0.053399168864416424\n",
      "epoch: 5, loss: 0.04389452030591201\n",
      "epoch: 6, loss: 0.04468576897488674\n",
      "epoch: 7, loss: 0.041547041888406966\n",
      "epoch: 8, loss: 0.04280486659263261\n",
      "epoch: 9, loss: 0.037350316233641934\n",
      "epoch: 10, loss: 0.03816264238412259\n",
      "epoch: 11, loss: 0.03806404880742775\n",
      "epoch: 12, loss: 0.037109643235453404\n",
      "epoch: 13, loss: 0.03673891281505348\n",
      "epoch: 14, loss: 0.0349240052382811\n",
      "epoch: 15, loss: 0.034368059954431374\n",
      "epoch: 16, loss: 0.03619111427542521\n",
      "epoch: 17, loss: 0.03380325317266397\n",
      "epoch: 18, loss: 0.03443464187148493\n",
      "epoch: 19, loss: 0.03345944303146098\n",
      "epoch: 20, loss: 0.03072876659280155\n",
      "epoch: 21, loss: 0.032489329620148055\n",
      "epoch: 22, loss: 0.03167817380017368\n",
      "epoch: 23, loss: 0.029995505188708194\n",
      "epoch: 24, loss: 0.029377883598499466\n",
      "epoch: 25, loss: 0.030021673373994417\n",
      "epoch: 26, loss: 0.02931614514091052\n",
      "epoch: 27, loss: 0.028412389940058347\n",
      "epoch: 28, loss: 0.030767115582420956\n",
      "epoch: 29, loss: 0.027663967968692305\n",
      "epoch: 30, loss: 0.028043733345839428\n",
      "epoch: 31, loss: 0.027345567523298087\n",
      "epoch: 32, loss: 0.026824638749531005\n",
      "epoch: 33, loss: 0.027795836635050364\n",
      "epoch: 34, loss: 0.02557802352021099\n",
      "epoch: 35, loss: 0.02605273971130373\n",
      "epoch: 36, loss: 0.025442947593546705\n",
      "epoch: 37, loss: 0.025558746034221258\n",
      "epoch: 38, loss: 0.025504152155917836\n",
      "epoch: 39, loss: 0.023911805597890634\n",
      "epoch: 40, loss: 0.024196772148570744\n",
      "epoch: 41, loss: 0.02421961499931058\n",
      "epoch: 42, loss: 0.0249738556885859\n",
      "epoch: 43, loss: 0.024712509188248077\n",
      "epoch: 44, loss: 0.022878674088133266\n",
      "epoch: 45, loss: 0.023658386282477295\n",
      "epoch: 46, loss: 0.022718590753356693\n",
      "epoch: 47, loss: 0.0219989584547875\n",
      "epoch: 48, loss: 0.02176565541230957\n",
      "epoch: 49, loss: 0.02327860215882538\n",
      "epoch: 50, loss: 0.022344555338349892\n",
      "epoch: 51, loss: 0.022021649205271387\n",
      "epoch: 52, loss: 0.02054121589026181\n",
      "epoch: 53, loss: 0.021235438300209353\n",
      "epoch: 54, loss: 0.021637375859427266\n",
      "epoch: 55, loss: 0.02112727447092766\n",
      "epoch: 56, loss: 0.01894413119953242\n",
      "epoch: 57, loss: 0.020979923610866535\n",
      "epoch: 58, loss: 0.019528196811734233\n",
      "epoch: 59, loss: 0.020117256695812102\n",
      "epoch: 60, loss: 0.019034845394344302\n",
      "epoch: 61, loss: 0.018125844377209432\n",
      "epoch: 62, loss: 0.019327006721141515\n",
      "epoch: 63, loss: 0.019096166997769615\n",
      "epoch: 64, loss: 0.017716115249641007\n",
      "epoch: 65, loss: 0.017890997369249817\n",
      "epoch: 66, loss: 0.017707495841023047\n",
      "epoch: 67, loss: 0.017936607877345523\n",
      "epoch: 68, loss: 0.017500475547421956\n",
      "epoch: 69, loss: 0.017485523039795225\n",
      "epoch: 70, loss: 0.016139379267769982\n",
      "epoch: 71, loss: 0.016584919609158533\n",
      "epoch: 72, loss: 0.016761155631684233\n",
      "epoch: 73, loss: 0.016998257338855183\n",
      "epoch: 74, loss: 0.016349959219951415\n",
      "epoch: 75, loss: 0.015360188153863419\n",
      "epoch: 76, loss: 0.01609350004582666\n",
      "epoch: 77, loss: 0.01558960846523405\n",
      "epoch: 78, loss: 0.015599801226926502\n",
      "epoch: 79, loss: 0.015673207977670245\n",
      "epoch: 80, loss: 0.014386978280526819\n",
      "epoch: 81, loss: 0.014392859435247374\n",
      "epoch: 82, loss: 0.014386751452548197\n",
      "epoch: 83, loss: 0.015309976417483995\n",
      "epoch: 84, loss: 0.014433201802603435\n",
      "epoch: 85, loss: 0.013619955114336335\n",
      "epoch: 86, loss: 0.013472684287989978\n",
      "epoch: 87, loss: 0.012436393608368235\n",
      "epoch: 88, loss: 0.014131000263660098\n",
      "epoch: 89, loss: 0.01363203683285974\n",
      "epoch: 90, loss: 0.013553791626691236\n",
      "epoch: 91, loss: 0.013213323349191342\n",
      "epoch: 92, loss: 0.012865564542153152\n",
      "epoch: 93, loss: 0.013458179819281213\n",
      "epoch: 94, loss: 0.012406511425069766\n",
      "epoch: 95, loss: 0.012256477546543465\n",
      "epoch: 96, loss: 0.012384256839141017\n",
      "epoch: 97, loss: 0.012340722561930306\n",
      "epoch: 98, loss: 0.01233724400299252\n",
      "epoch: 99, loss: 0.013178512555896305\n",
      "..Regressor testing started..\n",
      "MSE: 0.00018825751659565677\n",
      "Image_num || Mean a || Mean b\n",
      "Image: 1 mean_a: 14.63144165277481 mean_b:11.418014883995056\n",
      "Image: 2 mean_a: 12.434901118278503 mean_b:12.689396262168884\n",
      "Image: 3 mean_a: 13.31686419248581 mean_b:11.21999990940094\n",
      "Image: 4 mean_a: 12.555567443370819 mean_b:9.273881137371063\n",
      "Image: 5 mean_a: 13.645181775093079 mean_b:8.804879903793335\n",
      "Image: 6 mean_a: 14.548454105854034 mean_b:11.436010718345642\n",
      "Image: 7 mean_a: 13.474358141422272 mean_b:14.104713916778564\n",
      "Image: 8 mean_a: 13.856100857257843 mean_b:14.752594351768494\n",
      "Image: 9 mean_a: 11.716283679008484 mean_b:10.168991506099701\n",
      "Image: 10 mean_a: 17.488158762454987 mean_b:12.221854150295258\n",
      "Image: 11 mean_a: 17.477610528469086 mean_b:12.01923382282257\n",
      "Image: 12 mean_a: 14.910209894180298 mean_b:12.145371854305267\n",
      "Image: 13 mean_a: 12.971417129039764 mean_b:11.483644962310791\n",
      "Image: 14 mean_a: 13.895421147346497 mean_b:10.11529278755188\n",
      "Image: 15 mean_a: 13.264320611953735 mean_b:14.077780961990356\n",
      "Image: 16 mean_a: 12.836630761623383 mean_b:10.817115128040314\n",
      "Image: 17 mean_a: 13.701373159885406 mean_b:14.056350111961365\n",
      "Image: 18 mean_a: 13.87856525182724 mean_b:11.470056891441345\n",
      "Image: 19 mean_a: 13.519910097122192 mean_b:11.804788529872894\n",
      "Image: 20 mean_a: 16.850233793258667 mean_b:10.448185324668884\n",
      "Image: 21 mean_a: 14.101765275001526 mean_b:11.36515212059021\n",
      "Image: 22 mean_a: 16.9857497215271 mean_b:11.44751650094986\n",
      "Image: 23 mean_a: 15.130035698413849 mean_b:11.460086226463318\n",
      "Image: 24 mean_a: 13.086034178733826 mean_b:11.859034419059753\n",
      "Image: 25 mean_a: 12.976402461528778 mean_b:14.748824954032898\n",
      "Image: 26 mean_a: 19.573547661304474 mean_b:15.217096626758575\n",
      "Image: 27 mean_a: 15.536568284034729 mean_b:12.345469117164612\n",
      "Image: 28 mean_a: 12.038172006607056 mean_b:10.537951707839966\n",
      "Image: 29 mean_a: 13.672433912754059 mean_b:12.514271259307861\n",
      "Image: 30 mean_a: 17.74444741010666 mean_b:12.572620928287506\n",
      "Image: 31 mean_a: 14.017820179462433 mean_b:12.154552161693573\n",
      "Image: 32 mean_a: 14.303078472614288 mean_b:13.224711537361145\n",
      "Image: 33 mean_a: 15.56147974729538 mean_b:17.80722004175186\n",
      "Image: 34 mean_a: 11.566921293735504 mean_b:11.853562712669373\n",
      "Image: 35 mean_a: 12.526157021522522 mean_b:10.508571684360504\n",
      "Image: 36 mean_a: 13.33850783109665 mean_b:11.384409487247467\n",
      "Image: 37 mean_a: 15.11933547258377 mean_b:13.421753764152527\n",
      "Image: 38 mean_a: 13.922110915184021 mean_b:13.884964108467102\n",
      "Image: 39 mean_a: 15.085365295410156 mean_b:15.404867351055145\n",
      "Image: 40 mean_a: 12.5909663438797 mean_b:12.707984864711761\n",
      "Image: 41 mean_a: 16.44329082965851 mean_b:13.5109121799469\n",
      "Image: 42 mean_a: 14.695931792259216 mean_b:15.10605138540268\n",
      "Image: 43 mean_a: 12.578031837940216 mean_b:13.358418762683868\n",
      "Image: 44 mean_a: 14.358297109603882 mean_b:12.925606787204742\n",
      "Image: 45 mean_a: 14.71274209022522 mean_b:15.189570903778076\n",
      "Image: 46 mean_a: 14.093846499919891 mean_b:13.26448780298233\n",
      "Image: 47 mean_a: 15.28105479478836 mean_b:11.081504940986633\n",
      "Image: 48 mean_a: 13.10143095254898 mean_b:13.990324854850769\n",
      "Image: 49 mean_a: 13.837785840034485 mean_b:10.969623744487762\n",
      "Image: 50 mean_a: 15.8445645570755 mean_b:11.554047584533691\n",
      "Image: 51 mean_a: 14.19098448753357 mean_b:11.603444933891296\n",
      "Image: 52 mean_a: 12.4597669839859 mean_b:12.641108453273773\n",
      "Image: 53 mean_a: 16.086657166481018 mean_b:11.409685730934143\n",
      "Image: 54 mean_a: 12.88361144065857 mean_b:13.790288388729095\n",
      "Image: 55 mean_a: 15.5124471783638 mean_b:11.962024092674255\n",
      "Image: 56 mean_a: 14.198948860168457 mean_b:11.698485434055328\n",
      "Image: 57 mean_a: 13.38573169708252 mean_b:15.337550163269043\n",
      "Image: 58 mean_a: 13.479753851890564 mean_b:11.640850126743317\n",
      "Image: 59 mean_a: 13.726345419883728 mean_b:13.334312856197357\n",
      "Image: 60 mean_a: 15.315769731998444 mean_b:12.410384833812714\n",
      "Image: 61 mean_a: 16.558743834495544 mean_b:15.050711154937744\n",
      "Image: 62 mean_a: 15.521232306957245 mean_b:12.624541342258453\n",
      "Image: 63 mean_a: 12.191790163516998 mean_b:11.365471303462982\n",
      "Image: 64 mean_a: 13.779451370239258 mean_b:9.299628555774689\n",
      "Image: 65 mean_a: 11.975703358650208 mean_b:15.183977603912354\n",
      "Image: 66 mean_a: 16.398559629917145 mean_b:13.209998726844788\n",
      "Image: 67 mean_a: 14.099850177764893 mean_b:10.864931762218475\n",
      "Image: 68 mean_a: 15.956035375595093 mean_b:11.603034555912018\n",
      "Image: 69 mean_a: 12.921259820461273 mean_b:13.20276391506195\n",
      "Image: 70 mean_a: 16.189950823783875 mean_b:11.319493770599365\n",
      "Image: 71 mean_a: 12.617990493774414 mean_b:12.557041764259338\n",
      "Image: 72 mean_a: 13.991282403469086 mean_b:12.618993639945984\n",
      "Image: 73 mean_a: 12.392267405986786 mean_b:13.886940002441406\n",
      "Image: 74 mean_a: 12.116417407989502 mean_b:12.32958596944809\n",
      "Image: 75 mean_a: 12.310359001159668 mean_b:12.008943974971771\n",
      "For Tanh Function\n",
      "Device: cpu\n",
      "Length of Augmented Dataset 6740\n",
      "Activation Function:  tanh\n",
      "..Colorizer Training started..\n",
      "epoch: 0, loss: 10.144837719853967\n",
      "epoch: 1, loss: 0.6641749975970015\n",
      "epoch: 2, loss: 0.3137222061632201\n",
      "epoch: 3, loss: 0.2295385403558612\n",
      "epoch: 4, loss: 0.16128255269723013\n",
      "epoch: 5, loss: 0.13693495886400342\n",
      "epoch: 6, loss: 0.11786517634755\n",
      "epoch: 7, loss: 0.10963173938216642\n",
      "epoch: 8, loss: 0.09663081474718638\n",
      "epoch: 9, loss: 0.08967240460333414\n",
      "epoch: 10, loss: 0.08413994987495244\n",
      "epoch: 11, loss: 0.07927323578041978\n",
      "epoch: 12, loss: 0.07626517242169939\n",
      "epoch: 13, loss: 0.07293824994121678\n",
      "epoch: 14, loss: 0.07129212096333504\n",
      "epoch: 15, loss: 0.06938615854596719\n",
      "epoch: 16, loss: 0.07226148678455502\n",
      "epoch: 17, loss: 0.06588630430633202\n",
      "epoch: 18, loss: 0.06407296803081408\n",
      "epoch: 19, loss: 0.06083041585225146\n",
      "epoch: 20, loss: 0.06408235066919588\n",
      "epoch: 21, loss: 0.058059652568772435\n",
      "epoch: 22, loss: 0.057358098798431456\n",
      "epoch: 23, loss: 0.05574862634239253\n",
      "epoch: 24, loss: 0.05618629681703169\n",
      "epoch: 25, loss: 0.05267318416736089\n",
      "epoch: 26, loss: 0.0549739057169063\n",
      "epoch: 27, loss: 0.052454613003646955\n",
      "epoch: 28, loss: 0.05171748842985835\n",
      "epoch: 29, loss: 0.04962561021966394\n",
      "epoch: 30, loss: 0.04877335841592867\n",
      "epoch: 31, loss: 0.047069200285477564\n",
      "epoch: 32, loss: 0.04894221563881729\n",
      "epoch: 33, loss: 0.050842360316892155\n",
      "epoch: 34, loss: 0.04663638968486339\n",
      "epoch: 35, loss: 0.045390668616164476\n",
      "epoch: 36, loss: 0.04589785126154311\n",
      "epoch: 37, loss: 0.04890680278185755\n",
      "epoch: 38, loss: 0.04452081558702048\n",
      "epoch: 39, loss: 0.04535017545276787\n",
      "epoch: 40, loss: 0.04305763196316548\n",
      "epoch: 41, loss: 0.042098886930034496\n",
      "epoch: 42, loss: 0.042519831520621665\n",
      "epoch: 43, loss: 0.04164559593482409\n",
      "epoch: 44, loss: 0.04304488401976414\n",
      "epoch: 45, loss: 0.041759547384572215\n",
      "epoch: 46, loss: 0.043129186815349385\n",
      "epoch: 47, loss: 0.040657150821061805\n",
      "epoch: 48, loss: 0.04048158360819798\n",
      "epoch: 49, loss: 0.0396146182611119\n",
      "epoch: 50, loss: 0.040567081814515404\n",
      "epoch: 51, loss: 0.03976654104189947\n",
      "epoch: 52, loss: 0.03837288042996079\n",
      "epoch: 53, loss: 0.03787766944151372\n",
      "epoch: 54, loss: 0.03911241034802515\n",
      "epoch: 55, loss: 0.0383821726863971\n",
      "epoch: 56, loss: 0.04371397121576592\n",
      "epoch: 57, loss: 0.03916132266749628\n",
      "epoch: 58, loss: 0.03748153078049654\n",
      "epoch: 59, loss: 0.035637250846775714\n",
      "epoch: 60, loss: 0.03608907025773078\n",
      "epoch: 61, loss: 0.034755203138047364\n",
      "epoch: 62, loss: 0.03645002054690849\n",
      "epoch: 63, loss: 0.03555044035601895\n",
      "epoch: 64, loss: 0.03488554769865004\n",
      "epoch: 65, loss: 0.03387322090566158\n",
      "epoch: 66, loss: 0.03535201791237341\n",
      "epoch: 67, loss: 0.034149574777984526\n",
      "epoch: 68, loss: 0.03361592768487753\n",
      "epoch: 69, loss: 0.03401500838663196\n",
      "epoch: 70, loss: 0.0341099887737073\n",
      "epoch: 71, loss: 0.03269697237556102\n",
      "epoch: 72, loss: 0.0331269124726532\n",
      "epoch: 73, loss: 0.03298303795600077\n",
      "epoch: 74, loss: 0.03237355544115417\n",
      "epoch: 75, loss: 0.03441050719266059\n",
      "epoch: 76, loss: 0.032779813758679666\n",
      "epoch: 77, loss: 0.031023112911498174\n",
      "epoch: 78, loss: 0.03158428538154112\n",
      "epoch: 79, loss: 0.031132145806623157\n",
      "epoch: 80, loss: 0.031626115436665714\n",
      "epoch: 81, loss: 0.03203272712562466\n",
      "epoch: 82, loss: 0.03111974116472993\n",
      "epoch: 83, loss: 0.03106946189654991\n",
      "epoch: 84, loss: 0.030328357381222304\n",
      "epoch: 85, loss: 0.030587671368266456\n",
      "epoch: 86, loss: 0.030482083384413272\n",
      "epoch: 87, loss: 0.03125714462657925\n",
      "epoch: 88, loss: 0.029897465457906947\n",
      "epoch: 89, loss: 0.030597287252021488\n",
      "epoch: 90, loss: 0.030493020545691252\n",
      "epoch: 91, loss: 0.030592821531172376\n",
      "epoch: 92, loss: 0.03006577455380466\n",
      "epoch: 93, loss: 0.02990065440098988\n",
      "epoch: 94, loss: 0.02991192555782618\n",
      "epoch: 95, loss: 0.029598771514429245\n",
      "epoch: 96, loss: 0.030506370421790052\n",
      "epoch: 97, loss: 0.03038483134150738\n",
      "epoch: 98, loss: 0.02903833351592766\n",
      "epoch: 99, loss: 0.02976058507920243\n",
      "tanh\n",
      "..Colorizer Test started..\n",
      "Image: 1, loss: 0.005508818197995424\n",
      "Image: 2, loss: 0.005234677344560623\n",
      "Image: 3, loss: 0.005190281197428703\n",
      "Image: 4, loss: 0.005943625699728727\n",
      "Image: 5, loss: 0.005242168437689543\n",
      "Image: 6, loss: 0.005166511982679367\n",
      "Image: 7, loss: 0.005796059966087341\n",
      "Image: 8, loss: 0.002056649187579751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 25 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 9 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 214 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 23 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 24 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 9, loss: 0.006483137141913176\n",
      "Image: 10, loss: 0.005137956701219082\n",
      "Image: 11, loss: 0.005586415063589811\n",
      "Image: 12, loss: 0.0012310643214732409\n",
      "Image: 13, loss: 0.0008043824345804751\n",
      "Image: 14, loss: 0.005660770460963249\n",
      "Image: 15, loss: 0.00538567965850234\n",
      "Image: 16, loss: 0.005470099858939648\n",
      "Image: 17, loss: 0.005555180367082357\n",
      "Image: 18, loss: 0.005698667839169502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 29 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 3 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 8 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 99 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 20 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 13 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 19, loss: 0.00594860827550292\n",
      "Image: 20, loss: 0.005106506869196892\n",
      "Image: 21, loss: 0.005129218567162752\n",
      "Image: 22, loss: 0.007106900215148926\n",
      "Image: 23, loss: 0.0014822264201939106\n",
      "Image: 24, loss: 0.00523366779088974\n",
      "Image: 25, loss: 0.005181462503969669\n",
      "Image: 26, loss: 0.005661866627633572\n",
      "Image: 27, loss: 0.0054477304220199585\n",
      "Image: 28, loss: 0.0055845570750534534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 45 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 28 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 6 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 67 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 15 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 5 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 11 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 32 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 7 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 29, loss: 0.005146740935742855\n",
      "Image: 30, loss: 0.005187545903027058\n",
      "Image: 31, loss: 0.005367855541408062\n",
      "Image: 32, loss: 0.005608506500720978\n",
      "Image: 33, loss: 0.005717557389289141\n",
      "Image: 34, loss: 0.005735503509640694\n",
      "Image: 35, loss: 0.0052818069234490395\n",
      "Image: 36, loss: 0.005493106320500374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 30 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 211 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 26 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 37, loss: 0.005878419615328312\n",
      "Image: 38, loss: 0.005100314971059561\n",
      "Image: 39, loss: 0.005839621182531118\n",
      "Image: 40, loss: 0.006768431514501572\n",
      "Image: 41, loss: 0.0030112392269074917\n",
      "Image: 42, loss: 0.005234632175415754\n",
      "Image: 43, loss: 0.0013453926658257842\n",
      "Image: 44, loss: 0.005221450701355934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 233 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 27 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 45, loss: 0.004436417482793331\n",
      "Image: 46, loss: 0.005310961045324802\n",
      "Image: 47, loss: 0.006354288198053837\n",
      "Image: 48, loss: 0.005418005865067244\n",
      "Image: 49, loss: 0.0014435818884521723\n",
      "Image: 50, loss: 0.005060959607362747\n",
      "Image: 51, loss: 0.006094373296946287\n",
      "Image: 52, loss: 0.0006204867386259139\n",
      "Image: 53, loss: 0.005379248410463333\n",
      "Image: 54, loss: 0.0025223903357982635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 12 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 14 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 18 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 170 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 55, loss: 0.005356137175112963\n",
      "Image: 56, loss: 0.0014767830725759268\n",
      "Image: 57, loss: 0.005153649486601353\n",
      "Image: 58, loss: 0.005035740323364735\n",
      "Image: 59, loss: 0.005575147923082113\n",
      "Image: 60, loss: 0.0032167367171496153\n",
      "Image: 61, loss: 0.0021210452541708946\n",
      "Image: 62, loss: 0.0057114772498607635\n",
      "Image: 63, loss: 0.004222855903208256\n",
      "Image: 64, loss: 0.0010976113844662905\n",
      "Image: 65, loss: 0.005160581320524216\n",
      "Image: 66, loss: 0.004951666109263897\n",
      "Image: 67, loss: 0.0054189725778996944\n",
      "Image: 68, loss: 0.005304670426994562\n",
      "Image: 69, loss: 0.005579458083957434\n",
      "Image: 70, loss: 0.005623349919915199\n",
      "Image: 71, loss: 0.005739803425967693\n",
      "Image: 72, loss: 0.005717047024518251\n",
      "Image: 73, loss: 0.0005339409690350294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 52 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 48 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 57 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 74 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 74, loss: 0.0051225051283836365\n",
      "Image: 75, loss: 0.004936813376843929\n",
      "Image: 76, loss: 0.005144359543919563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/skimage/color/colorconv.py:988: UserWarning: Color data out of range: Z < 0 in 169 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Regressor training started..\n",
      "epoch: 0, loss: 0.5717732312332373\n",
      "epoch: 1, loss: 0.09392995733651333\n",
      "epoch: 2, loss: 0.0671872399689164\n",
      "epoch: 3, loss: 0.06465603925607866\n",
      "epoch: 4, loss: 0.05074049088580068\n",
      "epoch: 5, loss: 0.04779794403293636\n",
      "epoch: 6, loss: 0.04532484447554452\n",
      "epoch: 7, loss: 0.04570005225104978\n",
      "epoch: 8, loss: 0.04327818760066293\n",
      "epoch: 9, loss: 0.04007332924811635\n",
      "epoch: 10, loss: 0.04015361259371275\n",
      "epoch: 11, loss: 0.03836951541597955\n",
      "epoch: 12, loss: 0.0402200901080505\n",
      "epoch: 13, loss: 0.03572043596068397\n",
      "epoch: 14, loss: 0.03798083858418977\n",
      "epoch: 15, loss: 0.035295765614137053\n",
      "epoch: 16, loss: 0.03705608270684024\n",
      "epoch: 17, loss: 0.03266946033545537\n",
      "epoch: 18, loss: 0.03300997432961594\n",
      "epoch: 19, loss: 0.030668789280753117\n",
      "epoch: 20, loss: 0.03170675207366003\n",
      "epoch: 21, loss: 0.029931073600891978\n",
      "epoch: 22, loss: 0.03237729961256264\n",
      "epoch: 23, loss: 0.03216975018585799\n",
      "epoch: 24, loss: 0.03024582832949818\n",
      "epoch: 25, loss: 0.030801564258581493\n",
      "epoch: 26, loss: 0.02892715922644129\n",
      "epoch: 27, loss: 0.031001964896859135\n",
      "epoch: 28, loss: 0.030716007328010164\n",
      "epoch: 29, loss: 0.02830593808539561\n",
      "epoch: 30, loss: 0.028153026862128172\n",
      "epoch: 31, loss: 0.028295779513427988\n",
      "epoch: 32, loss: 0.029539641189330723\n",
      "epoch: 33, loss: 0.02772790727976826\n",
      "epoch: 34, loss: 0.02644765732839005\n",
      "epoch: 35, loss: 0.027241753345151665\n",
      "epoch: 36, loss: 0.026429937723150942\n",
      "epoch: 37, loss: 0.024618805156933377\n",
      "epoch: 38, loss: 0.027008709927031305\n",
      "epoch: 39, loss: 0.025950621791707817\n",
      "epoch: 40, loss: 0.02499988210547599\n",
      "epoch: 41, loss: 0.026747175372292986\n",
      "epoch: 42, loss: 0.025324394140625373\n",
      "epoch: 43, loss: 0.0237500301846012\n",
      "epoch: 44, loss: 0.024747053594182944\n",
      "epoch: 45, loss: 0.023244488274940522\n",
      "epoch: 46, loss: 0.023248728015460074\n",
      "epoch: 47, loss: 0.024400578426138964\n",
      "epoch: 48, loss: 0.023714945487881778\n",
      "epoch: 49, loss: 0.022943360138015123\n",
      "epoch: 50, loss: 0.02372699949410162\n",
      "epoch: 51, loss: 0.021175238478463143\n",
      "epoch: 52, loss: 0.022426977462600917\n",
      "epoch: 53, loss: 0.020727207698655548\n",
      "epoch: 54, loss: 0.022361311039276188\n",
      "epoch: 55, loss: 0.021031809508713195\n",
      "epoch: 56, loss: 0.02107389206503285\n",
      "epoch: 57, loss: 0.01953513918851968\n",
      "epoch: 58, loss: 0.020875692116533173\n",
      "epoch: 59, loss: 0.020565007067489205\n",
      "epoch: 60, loss: 0.01921193993621273\n",
      "epoch: 61, loss: 0.019473306190775475\n",
      "epoch: 62, loss: 0.01880466336660902\n",
      "epoch: 63, loss: 0.019068854529905366\n",
      "epoch: 64, loss: 0.020545554802083643\n",
      "epoch: 65, loss: 0.018320287272217683\n",
      "epoch: 66, loss: 0.017414078865840565\n",
      "epoch: 67, loss: 0.01801742516181548\n",
      "epoch: 68, loss: 0.017994440837355796\n",
      "epoch: 69, loss: 0.01768328515390749\n",
      "epoch: 70, loss: 0.016892457591893617\n",
      "epoch: 71, loss: 0.01792184536679997\n",
      "epoch: 72, loss: 0.01632566661282908\n",
      "epoch: 73, loss: 0.016535575115995016\n",
      "epoch: 74, loss: 0.01751506986329332\n",
      "epoch: 75, loss: 0.017453039316023933\n",
      "epoch: 76, loss: 0.015724385793873807\n",
      "epoch: 77, loss: 0.015196538201053045\n",
      "epoch: 78, loss: 0.01550820549527998\n",
      "epoch: 79, loss: 0.01582636278908467\n",
      "epoch: 80, loss: 0.015184105563093908\n",
      "epoch: 81, loss: 0.016707284203221207\n",
      "epoch: 82, loss: 0.015132503209315473\n",
      "epoch: 83, loss: 0.014077276040552533\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import os\n",
    "import re\n",
    "from shutil import copy2\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import lab2rgb\n",
    "from skimage.color import rgb2lab, rgb2gray\n",
    "from torchvision import datasets\n",
    "def data_load():\n",
    "    image_list = glob.glob('face_images/*.jpg')\n",
    "    print(\"Length of given Image List\", len(image_list))\n",
    "    train_test_split()\n",
    "    training_image_list = glob.glob('data/train/class/*.jpg')\n",
    "    test_image_list = glob.glob('data/test/class/*.jpg')\n",
    "    print(\"Length of training Image List\", len(training_image_list))\n",
    "    print(\"Length of testing Image List\", len(test_image_list))\n",
    "def train_test_split():\n",
    "        os.makedirs('data/train/class/', exist_ok=True)\n",
    "        os.makedirs('data/test/class/', exist_ok=True)\n",
    "        os.makedirs('Model/Colorizer/', exist_ok=True)\n",
    "        os.makedirs('Model/Regressor/', exist_ok=True)\n",
    "        os.makedirs('Plots/Colorizer/', exist_ok=True)\n",
    "        os.makedirs('outputs_sigmoid/gray/',exist_ok=True)\n",
    "        os.makedirs('outputs_sigmoid/color/',exist_ok=True)\n",
    "        os.makedirs('outputs_sigmoid/disp/',exist_ok=True)\n",
    "        os.makedirs('outputs_tanh/gray/',exist_ok=True)\n",
    "        os.makedirs('outputs_tanh/color/',exist_ok=True)\n",
    "\n",
    "\n",
    "        number_of_images = len(next(os.walk('face_images'))[2])\n",
    "        print(\"Number of images - \", number_of_images)\n",
    "\n",
    "        for i, file in enumerate(os.listdir('face_images')):\n",
    "            if i < (0.1 * number_of_images):\n",
    "                copy2('face_images/' + file, 'data/test/class/' + file)\n",
    "                continue\n",
    "            else: \n",
    "                copy2('face_images/' + file, 'data/train/class/' + file)\n",
    "\n",
    "        print(\"Training Set Size : \", len(next(os.walk('data/train/class'))[2]))\n",
    "        print(\"Test Set Size : \", len(next(os.walk('data/test/class'))[2]))\n",
    "def build_dataset(cuda=False, num_workers=1,\n",
    "                  activation_function=\"sigmoid\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(128)\n",
    "    ])\n",
    "\n",
    "    train_datasets = []\n",
    "    if activation_function == \"sigmoid\" or activation_function == 'tanh':\n",
    "        train_datasets.append(AugmentImageDataset('data/train'))\n",
    "    elif activation_function == \"relu\":\n",
    "        train_datasets.append(AugmentImageDataset_RELU('data/train'))\n",
    "\n",
    "    for i in range(9):\n",
    "        if activation_function == \"sigmoid\":\n",
    "            train_datasets.append(AugmentImageDataset('data/train', transform))\n",
    "        elif activation_function == \"relu\":\n",
    "            train_datasets.append(AugmentImageDataset_RELU('data/train', transform))\n",
    "        elif activation_function == \"tanh\":\n",
    "            train_datasets.append(AugmentImageDataset_Tanh('data/train',\n",
    "                                                                        transform))\n",
    "\n",
    "    augmented_dataset = ConcatDataset(train_datasets)\n",
    "    print(\"Length of Augmented Dataset\", len(augmented_dataset))\n",
    "\n",
    "    train_loader_args = dict(shuffle=True,\n",
    "                             batch_size=16,\n",
    "                             num_workers=num_workers, pin_memory=True) \\\n",
    "        if cuda else dict(shuffle=True, batch_size=32)\n",
    "\n",
    "    augmented_dataset_batch_train = DataLoader(dataset=augmented_dataset, **train_loader_args)\n",
    "    augmented_dataset_batch_test = DataLoader(dataset=AugmentImageDataset('data/test'))\n",
    "\n",
    "    return augmented_dataset_batch_train, augmented_dataset_batch_test\n",
    "\n",
    "def execution_colorizer_sigmoid():\n",
    "    activation_function = \"sigmoid\"\n",
    "    save_path = {'grayscale': 'outputs_sigmoid/gray/', 'colorized': 'outputs_sigmoid/color/'}\n",
    "    device, is_cuda_present, num_workers = get_device()\n",
    "    model_name = \"Model/Colorizer/Colorizer_sigmoid_epoch_{0}_lr_{1}_weight_decay_{2}.pth\"\n",
    "\n",
    "    print(\"Device: {0}\".format(device))\n",
    "    augmented_dataset_batch_train, \\\n",
    "    augmented_dataset_batch_test = build_dataset(is_cuda_present, num_workers,activation_function)\n",
    "\n",
    "    colorizer = Manage_Colorize()\n",
    "    colorizer.train(augmented_dataset_batch_train,activation_function, device)\n",
    "    colorizer.test(augmented_dataset_batch_test, activation_function,save_path, device)\n",
    "    train_regressor(augmented_dataset_batch_train, device)\n",
    "    test_regressor(augmented_dataset_batch_test, device)\n",
    "def execution_colorizer_tanh():\n",
    "    activation_function = \"tanh\"\n",
    "    save_path = {'grayscale': 'outputs_tanh/gray/', 'colorized': 'outputs_tanh/color/'}\n",
    "    device, is_cuda_present, num_workers = get_device()\n",
    "    model_name = \"Model/Colorizer/Colorizer_tanh_epoch_{0}_lr_{1}_weight_decay_{2}.pth\"\n",
    "\n",
    "    print(\"Device: {0}\".format(device))\n",
    "    augmented_dataset_batch_train, \\\n",
    "    augmented_dataset_batch_test = build_dataset(is_cuda_present, num_workers,activation_function)\n",
    "    colorizer = Manage_Colorize()\n",
    "    colorizer.train(augmented_dataset_batch_train,activation_function, device)\n",
    "    colorizer.test(augmented_dataset_batch_test, activation_function,save_path, device)\n",
    "    train_regressor(augmented_dataset_batch_train, device)\n",
    "    test_regressor(augmented_dataset_batch_test, device)\n",
    "    \n",
    "def train_regressor(augmented_dataset_batch_train, device):\n",
    "    data_loader = augmented_dataset_batch_train\n",
    "    saved_model_path = \"Model/Regressor/Regressor.pth\"\n",
    "    epochs = 100\n",
    "    lr = 0.0001\n",
    "    weight_decay = 1e-5\n",
    "    in_channel = 1\n",
    "    hidden_channel = 3\n",
    "    out_dims = 2\n",
    "    loss_plot_path = \"Model/Regressor/Regressor_Loss_plot.jpeg\"   \n",
    "\n",
    "    print(\"..Regressor training started..\")\n",
    "    model = Regressor(in_channel=in_channel,\n",
    "                        hidden_channel=hidden_channel,\n",
    "                        out_dims=out_dims,\n",
    "                        train_mode=\"regressor\").to(device)\n",
    "\n",
    "    lossF = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "    loss_train = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for batch in data_loader:\n",
    "            l_channel, a_channel, b_channel = batch\n",
    "            l_channel = l_channel.to(device)\n",
    "\n",
    "            a_b_mean = get_ab_mean(a_channel, b_channel)\n",
    "            a_b_mean_hat = model(l_channel)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                loss = lossF(a_b_mean_hat.float().cuda(),\n",
    "                                 a_b_mean.float().cuda()).to(device)\n",
    "            else:\n",
    "                loss = lossF(a_b_mean_hat.float(),\n",
    "                                a_b_mean.float()).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(\"epoch: {0}, loss: {1}\"\n",
    "                .format(epoch, total_loss))\n",
    "        loss_train.append(total_loss)\n",
    "\n",
    "    plot_loss_epoch(loss_train, loss_plot_path)\n",
    "    torch.save(model.state_dict(), saved_model_path)\n",
    "\n",
    "def test_regressor(augmented_dataset_batch_test, device):\n",
    "    data_loader = augmented_dataset_batch_test\n",
    "    saved_model_path = \"Model/Regressor/Regressor.pth\"\n",
    "    in_channel = 1\n",
    "    hidden_channel = 3\n",
    "    out_dims = 2\n",
    "\n",
    "    print(\"..Regressor testing started..\")\n",
    "\n",
    "    model = Regressor(in_channel=in_channel,\n",
    "                          hidden_channel=hidden_channel,\n",
    "                          out_dims=out_dims,\n",
    "                          train_mode=\"regressor\").to(device)\n",
    "    model.load_state_dict(torch.load(saved_model_path, map_location=device))\n",
    "\n",
    "    a_list = []\n",
    "    b_list = []\n",
    "    lossF = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    loss_train = []\n",
    "    for batch in data_loader:\n",
    "        l_channel, a_channel, b_channel = batch\n",
    "        l_channel = l_channel.to(device)\n",
    "\n",
    "        a_b_mean = get_ab_mean(a_channel, b_channel)\n",
    "        a_b_mean_hat = model(l_channel).detach()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            loss = lossF(a_b_mean_hat.float().cuda(),\n",
    "                             a_b_mean.float().cuda()).to(device)\n",
    "        else:\n",
    "            loss = lossF(a_b_mean_hat.float(),\n",
    "                             a_b_mean.float()).to(device)\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "        a_b_pred = a_b_mean_hat[0].cpu().numpy()\n",
    "        a_list.append(a_b_pred[0])\n",
    "        b_list.append(a_b_pred[1])\n",
    "\n",
    "    print(\"MSE:\", np.average(np.asarray(loss_train)))\n",
    "    print(\"Image_num || Mean a || Mean b\")\n",
    "    for i in range(1, len(a_list)):\n",
    "        print(\"Image: {0} mean_a: {1} mean_b:{2}\".format(\n",
    "            i, (a_list[i] * 255) - 128, (b_list[i] * 255) - 128\n",
    "        ))\n",
    "    \n",
    "def get_device():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    is_cuda_present = True if torch.cuda.is_available() else False\n",
    "    num_workers = 8 if is_cuda_present else 0\n",
    "    return device, is_cuda_present, num_workers\n",
    "class AugmentImageDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        global img_a, img_b, img_gray\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        img_lab = rgb2lab(np.asarray(img))\n",
    "        img_lab = img_lab + 128\n",
    "        img_lab = img_lab / 255\n",
    "        img_a = torch.from_numpy(img_lab[:, :, 1:2].transpose((2, 0, 1))).float() \n",
    "        img_b = torch.from_numpy(img_lab[:, :, 2:3].transpose((2, 0, 1))).float()\n",
    "        img_gray = torch.from_numpy(rgb2gray(np.asarray(img))).unsqueeze(0).float()\n",
    "        return img_gray, img_a, img_b\n",
    "\n",
    "class AugmentImageDataset_Tanh(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        global img_a, img_b, img_gray\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        img_lab = rgb2lab(np.asarray(img))\n",
    "        img_lab = img_lab + 128\n",
    "        img_lab = img_lab / 255\n",
    "        img_a = torch.from_numpy(img_lab[:, :, 1:2].transpose((2, 0, 1))).float()\n",
    "        img_b = torch.from_numpy(img_lab[:, :, 2:3].transpose((2, 0, 1))).float()\n",
    "        img_gray = torch.from_numpy(rgb2gray(np.asarray(img))).unsqueeze(0).float()\n",
    "        return img_gray, img_a, img_b\n",
    "\n",
    "class AugmentImageDataset_RELU(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        global img_a, img_b, img_gray\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        img_lab = rgb2lab(np.asarray(img))\n",
    "        img_a = torch.from_numpy(img_lab[:, :, 1:2].transpose((2, 0, 1))).float() \n",
    "        img_b = torch.from_numpy(img_lab[:, :, 2:3].transpose((2, 0, 1))).float()\n",
    "        img_gray = torch.from_numpy(rgb2gray(np.asarray(img))).unsqueeze(0).float()\n",
    "\n",
    "        return img_gray, img_a, img_b\n",
    "def get_ab_mean(a_channel, b_channel):\n",
    "    a_channel_mean = a_channel.mean(dim=(2, 3))\n",
    "    b_channel_mean = b_channel.mean(dim=(2, 3))\n",
    "    a_b_mean = torch.cat([a_channel_mean,\n",
    "                              b_channel_mean], dim=1)\n",
    "    return a_b_mean\n",
    "def plot_loss_epoch(train_loss_avg, fig_name):\n",
    "    plt.ion()\n",
    "    fig = plt.figure()\n",
    "    plt.plot(train_loss_avg)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.draw()\n",
    "    plt.savefig(fig_name, dpi=220)\n",
    "    plt.clf()\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, in_channel=1, hidden_channel=3, out_dims=2,\n",
    "                 train_mode=\"regressor\"):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "        self.feature_maps = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channel, out_channels=32,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=256,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        if self.train_mode == \"regressor\":\n",
    "            self.lin = nn.Linear(in_features=512 * 2 * 2, out_features=out_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_maps = self.feature_maps(x)\n",
    "        if self.train_mode == \"regressor\":\n",
    "            y_hat = torch.sigmoid(self.lin(feature_maps.reshape(-1, 512 * 2 * 2)))\n",
    "            return y_hat\n",
    "\n",
    "        else:\n",
    "            return feature_maps\n",
    "\n",
    "class Colorizer(nn.Module):\n",
    "    def __init__(self, in_channel=3, hidden_channel=3, out_channel=2,\n",
    "                 activation_function=\"sigmoid\"):\n",
    "        super(Colorizer, self).__init__()\n",
    "        self.activation_function = activation_function\n",
    "        self.feature_maps = Regressor(in_channel=1, hidden_channel=3, out_dims=2,\n",
    "                                      train_mode=\"colorizer\")\n",
    "        self.up_sample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=out_channel,\n",
    "                               kernel_size=4, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            return torch.sigmoid(self.up_sample(self.feature_maps(x)))\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            return torch.tanh(self.up_sample(self.feature_maps(x)))\n",
    "        elif self.activation_function == \"relu\":\n",
    "            return torch.relu(self.up_sample(self.feature_maps(x)))\n",
    "\n",
    "def show_img(image):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    np_img = image.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "def to_rgb(grayscale_input, ab_input, activation_function=\"tanh\",\n",
    "               save_path=None, save_name=None, device=\"cpu\"):\n",
    "    plt.clf()\n",
    "    color_image = torch.cat((grayscale_input, ab_input), 0).numpy()  # combine channels\n",
    "    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
    "    color_image = lab2rgb(color_image.astype(np.float64))\n",
    "    grayscale_input = grayscale_input.squeeze().numpy()\n",
    "    if save_path is not None and save_name is not None:\n",
    "        plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
    "        plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))\n",
    "def show_img_tensor(image):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "def show_output_image(gray, orig, recons, fig_name):\n",
    "    plt.clf()\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1, 3, 1)\n",
    "    plt.imshow(mpimg.imread(gray))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(1, 3, 2)\n",
    "    plt.imshow(mpimg.imread(orig))\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(1, 3, 3)\n",
    "    plt.imshow(mpimg.imread(recons))\n",
    "    plt.axis('off')\n",
    "    plt.draw()\n",
    "    plt.savefig(fig_name, dpi=220)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "class EarlyStopping_DCN:\n",
    "\n",
    "    def __init__(self, patience=7, verbose=False, delta=0,\n",
    "                 model_path=None,\n",
    "                 trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.model_path = model_path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f'Validation loss decreased ({self.val_loss_min} --> {val_loss}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.model_path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "class Manage_Colorize:\n",
    "    def train(self,augmented_dataset_batch_train, activation_function, device):\n",
    "        print(\"Activation Function: \", activation_function)\n",
    "\n",
    "        train_data_loader = augmented_dataset_batch_train\n",
    "        saved_model_path =\"Model/Colorizer/Colorizer_{0}.pth\".format(activation_function)\n",
    "\n",
    "        epochs = 100\n",
    "        lr = .0001\n",
    "        weight_decay = 1e-5\n",
    "        in_channel = 3\n",
    "        hidden_channel = 3\n",
    "        loss_plot_path = \"Model/Colorizer/Colorizer_Loss_plot_{0}.jpeg\".format(activation_function)\n",
    "\n",
    "        print(\"..Colorizer Training started..\")\n",
    "        model = Colorizer(in_channel=3, hidden_channel=3,\n",
    "                          activation_function=activation_function).to(device)\n",
    "\n",
    "        lossF = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                               weight_decay=weight_decay)\n",
    "        loss_train = []\n",
    "        early_stopping = EarlyStopping_DCN(patience=50, verbose=True,\n",
    "                                           model_path=saved_model_path)\n",
    "        for epoch in range(epochs):\n",
    "            total_loss_train = 0\n",
    "            total_loss_val = 0\n",
    "            model.train()\n",
    "\n",
    "            for batch in train_data_loader:\n",
    "                l_channel, a_channel, b_channel = batch\n",
    "                l_channel = l_channel.to(device)\n",
    "\n",
    "                a_b_channel = torch.cat([a_channel, b_channel], dim=1)\n",
    "                a_b_channel_hat = model(l_channel)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    loss = lossF(a_b_channel_hat.float().cuda(),\n",
    "                                 a_b_channel.float().cuda()).to(device)\n",
    "                else:\n",
    "                    loss = lossF(a_b_channel_hat.float(),\n",
    "                                 a_b_channel.float()).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss_train += loss.item()\n",
    "\n",
    "            print(\"epoch: {0}, loss: {1}\"\n",
    "                  .format(epoch, total_loss_train))\n",
    "            loss_train.append(total_loss_train)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        plot_loss_epoch(loss_train, loss_plot_path)\n",
    "        torch.save(model.state_dict(), saved_model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def validate(model, val_data_loader, lossF, device):\n",
    "        loss_valid = []\n",
    "        model.eval()\n",
    "\n",
    "        # val treated\n",
    "        for batch in val_data_loader:\n",
    "            l_channel, a_channel, b_channel = batch\n",
    "            l_channel = l_channel.to(device)\n",
    "\n",
    "            a_b_channel = torch.cat([a_channel, b_channel], dim=1)\n",
    "            a_b_channel_hat = model(l_channel)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                loss = lossF(a_b_channel_hat.float().cuda(),\n",
    "                             a_b_channel.float().cuda()).to(device)\n",
    "            else:\n",
    "                loss = lossF(a_b_channel_hat.float(),\n",
    "                             a_b_channel.float()).to(device)\n",
    "\n",
    "            loss_valid.append(loss.item())\n",
    "\n",
    "        valid_loss = np.average(loss_valid)\n",
    "        return valid_loss\n",
    "\n",
    "    def test(self, augmented_dataset_batch_train, activation_function, save_path,device):\n",
    "        print(activation_function)\n",
    "        data_loader = augmented_dataset_batch_train\n",
    "        saved_model_path =\"Model/Colorizer/Colorizer_{0}.pth\".format(activation_function)\n",
    "\n",
    "        epoch = 100\n",
    "        lr = .0001\n",
    "        weight_decay = 1e-5\n",
    "        in_channel = 3\n",
    "        hidden_channel = 3\n",
    "        loss_plot_path = \"Model/Colorizer/Colorizer_Loss_plot_{0}.jpeg\".format(activation_function)\n",
    "        \n",
    "\n",
    "        print(\"..Colorizer Test started..\")\n",
    "        model = Colorizer(in_channel=in_channel,\n",
    "                          hidden_channel=hidden_channel,\n",
    "                          activation_function=activation_function).to(device)\n",
    "        model.load_state_dict(torch.load(saved_model_path, map_location=device))\n",
    "\n",
    "        lossF = nn.MSELoss()\n",
    "        serial_num = 0\n",
    "        for batch in data_loader:\n",
    "            serial_num += 1\n",
    "            l_channel, a_channel, b_channel = batch\n",
    "            l_channel = l_channel.to(device)\n",
    "\n",
    "            a_b_channel = torch.cat([a_channel, b_channel], dim=1)\n",
    "            a_b_channel_hat = model(l_channel).detach()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                loss = lossF(a_b_channel_hat.float().cuda(),\n",
    "                             a_b_channel.float().cuda()).to(device)\n",
    "            else:\n",
    "                loss = lossF(a_b_channel_hat.float(),\n",
    "                             a_b_channel.float()).to(device)\n",
    "\n",
    "            print(\"Image: {0}, loss: {1}\".format(serial_num, loss.item()))\n",
    "\n",
    "            save_name_orig = 'Orig_img_epoch_{0}_lr_{1}_wt_decay{2}_serial_{3}_{4}.jpg' \\\n",
    "                .format(epoch, lr, weight_decay, serial_num,activation_function)\n",
    "            save_name_recons = 'Recons_img_epoch_{0}_lr_{1}_wt_decay{2}_serial_{3}_{4}.jpg' \\\n",
    "                .format(epoch, lr, weight_decay, serial_num,activation_function)\n",
    "\n",
    "            to_rgb(l_channel[0].cpu(), a_b_channel[0].cpu(),\n",
    "                         activation_function,\n",
    "                         save_path=save_path, save_name=save_name_orig, device=device)\n",
    "            to_rgb(l_channel[0].cpu(), a_b_channel_hat[0].cpu(),\n",
    "                         activation_function,\n",
    "                         save_path=save_path, save_name=save_name_recons, device=device)\n",
    "\n",
    "        self.show_final_image_grid(epoch, lr, weight_decay, save_path,activation_function)\n",
    "\n",
    "    @staticmethod\n",
    "    def show_final_image_grid(epoch, lr, weight_decay, save_path,activation_function):\n",
    "\n",
    "        color_path = save_path['colorized']\n",
    "        gray_path = save_path['grayscale']\n",
    "\n",
    "        for image_index in range(7, 70, 7):\n",
    "            title = \"Plots/Colorizer/epoch_{0}_lr_{1}_wt_{2}_serial_{3}_{4}.jpeg\".\\\n",
    "                format(epoch, lr, weight_decay, image_index,activation_function)\n",
    "\n",
    "            save_name_orig = 'Orig_img_epoch_{0}_lr_{1}_wt_decay{2}_serial_{3}_{4}.jpg' \\\n",
    "                .format(epoch, lr, weight_decay, image_index,activation_function)\n",
    "            save_name_recons = 'Recons_img_epoch_{0}_lr_{1}_wt_decay{2}_serial_{3}_{4}.jpg' \\\n",
    "                .format(epoch, lr, weight_decay, image_index,activation_function)\n",
    "            show_output_image(gray_path + save_name_orig, color_path + save_name_orig,\n",
    "                                    color_path + save_name_recons, title)\n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    data_load()\n",
    "\n",
    "    print(\"For Sigmoid Function\")\n",
    "    execution_colorizer_sigmoid()\n",
    "\n",
    "    print(\"For Tanh Function\")\n",
    "    execution_colorizer_tanh()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC-PyTorch-1.9",
   "language": "python",
   "name": "ngc-pytorch-1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
